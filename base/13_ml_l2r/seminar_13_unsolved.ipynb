{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8978a6-8494-42a0-84df-36569f26a074",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Семинар 13 - Ранжирование на деревянных моделях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254fb0b-17d4-47ab-9fc4-4a97c77bda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import dcg, ndcg\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e599fa-fb41-4e7d-8745-2fc9cb3ff7e1",
   "metadata": {
    "id": "IyKW4l6ZGsGO",
    "tags": []
   },
   "source": [
    "# ListNet\n",
    "\n",
    "\n",
    "Вспомним реализацию ListNet из прошлого семинара. Перенесем саму модель и инициализации ее весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f89b3-946a-4e9a-a9d7-e35f32729c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_1: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.model(input_1)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "def init_weights(module):\n",
    "    if isinstance(module, torch.nn.Embedding):\n",
    "        module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "        if module.padding_idx is not None:\n",
    "            module.weight.data[module.padding_idx].zero_()\n",
    "    elif isinstance(module, torch.nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "        \n",
    "        \n",
    "def create_model(listnet_num_input_features: int, listnet_hidden_dim: int) -> torch.nn.Module:\n",
    "    torch.manual_seed(0)\n",
    "    net = ListNet(listnet_num_input_features, listnet_hidden_dim)\n",
    "    init_weights(net)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246f6c0-f375-439e-9da3-5f642e424342",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Подготовка данных\n",
    "\n",
    "Обчение модели рандирования проведем на уменьшенной версии набора данных Microsoft Learning to Rank. Этот набор данных является уменьшенной версией набора данных msrank.\n",
    "\n",
    "Набор обучающих данных содержит 10000 объектов. Каждый объект описывается 138 колонками. Первый столбец содержит значение метки, второй — идентификатор группы объекта (GroupId). Все остальные столбцы содержат характеристики объектов.\n",
    "\n",
    "Валидационный набор данных содержит 10000 объектов. Структура идентична обучающему набору данных.\n",
    "\n",
    "Данные загрузим из ```catboost```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638a119-8a1e-4d8d-952c-80fd9f073778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data() -> List[np.ndarray]:\n",
    "    train_df, test_df = msrank_10k()\n",
    "\n",
    "    X_train = train_df.drop([0, 1], axis=1).values\n",
    "    y_train = train_df[0].values\n",
    "    query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "    X_test = test_df.drop([0, 1], axis=1).values\n",
    "    y_test = test_df[0].values\n",
    "    query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "    return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e88d-4ff0-474c-bbd1-f3032b1bb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, query_ids_train, X_test, y_test, query_ids_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09891046-bf5f-45bd-9e93-aad4d41138c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, query_ids_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d3d75-9252-401f-8a0a-9cba57d6eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(query_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5736e-25ca-4584-8eaa-a6cdbd110804",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ea9bb-b96c-4e08-acb7-cca55a9878fd",
   "metadata": {},
   "source": [
    "Проведем подготовку данных для обучения. Видно, что среднее и дисперсия в данных не идеальна. Исправим это для более устойчивого обучения модели. \n",
    "\n",
    "Затем подготовим данные для примения в обучении модели на ```torch```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15004d-de26-423d-a6e7-8ce1b5ff61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features_in_query_groups(inp_feat_array: np.ndarray, inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "    # your code here\n",
    "    # scale each data by query\n",
    "    for id in np.unique(inp_query_ids):\n",
    "        pass\n",
    "\n",
    "    return inp_feat_array\n",
    "\n",
    "\n",
    "def prepare_data() -> List[np.ndarray]:\n",
    "    X_train, y_train, query_ids_train, X_test, y_test, query_ids_test = get_data()\n",
    "    # your code here: \n",
    "    # 1. scale train and test data \n",
    "    # 2. convert data to torch\n",
    "    X_train = None\n",
    "    ys_train = None\n",
    "\n",
    "    X_test = None\n",
    "    ys_test = None\n",
    "    \n",
    "    return X_train, ys_train, query_ids_train, X_test, ys_test, query_ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f009f6-1f1c-4c03-b972-6ed10c20e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, ys_train, query_ids_train, X_test, ys_test, query_ids_test = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fda812-10ae-4cf1-ae10-48977d8ca4b2",
   "metadata": {},
   "source": [
    "## Подготовка этапов обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5f46a-4f11-43dd-9428-d1ca45f01c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_k(ys_true: torch.Tensor, ys_pred: torch.Tensor, ndcg_top_k: int) -> float:\n",
    "    try:\n",
    "        return ndcg(ys_true, ys_pred, gain_scheme='exp2', top_k=ndcg_top_k)\n",
    "    except ZeroDivisionError:\n",
    "        return float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f12da0-8893-482d-a3ce-bbd49c2bc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(batch_ys: torch.FloatTensor, batch_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "    P_y_i = torch.softmax(batch_ys, dim=0)\n",
    "    P_z_i = torch.softmax(batch_pred, dim=0)\n",
    "\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856312a7-5942-4d4d-bd26-3addb5313ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs: int = 5\n",
    "listnet_hidden_dim: int = 30\n",
    "lr: float = 0.001\n",
    "ndcg_top_k: int = 10\n",
    "num_input_features = X_train.shape[1]\n",
    "\n",
    "\n",
    "model = create_model(num_input_features, listnet_hidden_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86494c3-1136-4cd1-9b7f-3453570b77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_one_epoch(model, optimizer, X_train, ys_train, query_ids_train) -> None:\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0b5f4-2930-48fb-842a-d6389acb732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_one_epoch(model, optimizer, X_train, ys_train, query_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e6ee2-a317-48a7-bd5a-20ea929c5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_test_set(model, X_test, ys_test, query_ids_test) -> float:\n",
    "    # your code here\n",
    "    ndcgs = []\n",
    "\n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee4f25-657b-44b7-a9bf-2984f572844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_eval_test_set(model, X_test, ys_test, query_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d69d6-f3d4-447d-a88c-0f3f1970f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(n_epochs, model, optimizer, X_train, ys_train, query_ids_train, X_test, ys_test, query_ids_test) -> List[float]:\n",
    "    val_ndcg = []\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        _train_one_epoch(model, optimizer, X_train, ys_train, query_ids_train)\n",
    "        val_metric = _eval_test_set(model, X_test, ys_test, query_ids_test)\n",
    "\n",
    "        val_ndcg.append(val_metric)\n",
    "\n",
    "    return val_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1accc3db-f142-4069-9fa4-21a87a003c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs: int = 100\n",
    "listnet_hidden_dim: int = 10\n",
    "lr: float = 0.001\n",
    "ndcg_top_k: int = 10\n",
    "num_input_features = X_train.shape[1]\n",
    "\n",
    "\n",
    "model = create_model(num_input_features, listnet_hidden_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "val_ndcg = fit(n_epochs, model, optimizer, X_train, ys_train, query_ids_train, X_test, ys_test, query_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65424ac8-32e5-49ee-9b4b-8469b9c205ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_ndcg)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val/NDCG')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8ee98-2773-4371-b0b7-baf4883ef522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cef057b-e24c-409d-95bc-d5e5c622eb47",
   "metadata": {},
   "source": [
    "# LambdaRank\n",
    "\n",
    "$$\\lambda = \\left(0.5 * (1 - S_{ij}) - \\frac {1} {1 + e^{s_i - s_j}}\\right) |\\Delta nDCG|$$\n",
    "\n",
    "$$\\Delta nDCG = \\frac {1} {IdealDCG} (2^i - 2^j) \\left(\\frac {1} {log_2(1+i)} - \\frac {1} {log_2(1+j)}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f800d-36f0-4d1d-a32a-4f67ae976ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в y_true лежат оценки релевантности\n",
    "y_true = torch.LongTensor([[5, 3, 2, 5, 1, 1]]).reshape(-1, 1)\n",
    "y_pred = torch.FloatTensor([3.2, 0.4, -0.1, -2.1, 0.5, 0.01]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8e2eb-5e02-4297-9f66-7b7a46428adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b829d-10a4-4410-bfb8-1bda31db41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambdas(y_true, y_pred, ndcg_scheme='exp2'):\n",
    "    # рассчитаем нормировку, IdealDCG\n",
    "    ideal_dcg = dcg(y_true, y_true, ndcg_scheme)\n",
    "    N = 1 / ideal_dcg\n",
    "    \n",
    "    # рассчитаем порядок документов согласно оценкам релевантности\n",
    "    _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "    rank_order += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # получаем все попарные разницы скоров в батче\n",
    "        pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "        \n",
    "        # поставим разметку для пар, 1 если первый документ релевантнее\n",
    "        # -1 если второй документ релевантнее\n",
    "        Sij = compute_labels_in_batch(y_true)\n",
    "        # посчитаем изменение gain из-за перестановок\n",
    "        gain_diff = compute_gain_diff(y_true, ndcg_scheme)\n",
    "        \n",
    "        # посчитаем изменение знаменателей-дискаунтеров\n",
    "        decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "        # посчитаем непосредственное изменение nDCG\n",
    "        delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "        # посчитаем лямбды\n",
    "        lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "        lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "        \n",
    "        return Sij, gain_diff, decay_diff, delta_ndcg, lambda_update\n",
    "    \n",
    "    \n",
    "def compute_labels_in_batch(y_true):\n",
    "    \n",
    "    # разница релевантностей каждого с каждым объектом\n",
    "    rel_diff = y_true - y_true.t()\n",
    "    \n",
    "    # 1 в этой матрице - объект более релевантен\n",
    "    pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "    \n",
    "    # 1 тут - объект менее релевантен\n",
    "    neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "    Sij = pos_pairs - neg_pairs\n",
    "    return Sij\n",
    "\n",
    "\n",
    "def compute_gain_diff(y_true, gain_scheme):\n",
    "    if gain_scheme == \"exp2\":\n",
    "        gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "    elif gain_scheme == \"diff\":\n",
    "        gain_diff = y_true - y_true.t()\n",
    "    else:\n",
    "        raise ValueError(f\"{gain_scheme} method not supported\")\n",
    "    return gain_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5b176-e018-4c06-b4a8-9c81c3907d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred - y_pred.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28745f60-24a5-424b-80a1-282248d21613",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true - y_true.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ad15e-9e43-40b1-a393-7862f42e4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sij, gain_diff, decay_diff, delta_ndcg, lambda_update = compute_lambdas(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16fed2-f954-4624-8c26-ec8e83a4d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c579e60-21ee-4bcb-acce-866134a690bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e90a22-4bdf-4b60-9c7f-e707cc7c8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример вычисления элемента gain diff для первого (релевантность 5) и последнего документа (1); \n",
    "# для первого (5) и второго (3) документа\n",
    "(2**5 - 1) - (2**1 -1), (2**5 - 1) - (2**3-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a252b-9154-4e33-97a1-0084f5584151",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2dad0-5cc1-417b-aad9-fa11d0a819e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем изменение знаменателей-дискаунтеров для первого и последнего документа\n",
    "(1 / np.log2(1+1)) - (1 / np.log2(1+6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6250d0e-1678-4565-828d-335ed4c9edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afdcbc6-a399-41f7-94a8-54f351137fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06439056-4331-4bfa-ad18-d059f4279b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    _, _, _, _, lambda_update = compute_lambdas(y_true, y_pred)\n",
    "    y_pred -= lambda_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bd467-514b-4568-b82a-35e720acd8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_indexes = torch.argsort(y_pred, dim=0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e1be1-7954-4ad4-a9d7-c912ed997aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370382f1-9def-4cb5-9e1a-84b0f364e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[rank_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627f406-069a-420e-a632-a78e40cf6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# полностью правильное ранжирование\n",
    "torch.sort(y_true, dim=0, descending=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9b2d2-9e14-424a-8311-9528a97bdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.LongTensor([[5,3,2,5,1,1]]).reshape(-1,1)\n",
    "\n",
    "# совсем плохие предсказанные скоры в начале\n",
    "y_pred = torch.FloatTensor([-3.0, 2.0, 3.0, -4.0, 6.0, 8.5]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162f535-ede9-4abd-884b-ac37446333bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed0fd0-a8a6-4023-9d6a-7bf90001773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    _, _, _, _, lambda_update = compute_lambdas(y_true, y_pred)\n",
    "    y_pred -= lambda_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79e0b4-d2cc-44f7-9642-1a3a0b86c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19a733-9aa0-45cc-8abd-89aa53687dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# полностью правильное ранжирование при увеличении количества итераций\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59481d07-8c13-4410-97e1-279b1c5b2aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
